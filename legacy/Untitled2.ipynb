{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named gensim",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-79f5e786a2da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named gensim"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gensim, logging\n",
    "import csv, string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(317974, 1000)\n",
      "(317974, 1)\n",
      "(7215, 1000)\n",
      "(7215, 1)\n"
     ]
    }
   ],
   "source": [
    "training_arr = np.load(\"training_arr.npy\")\n",
    "print(training_arr.shape)\n",
    "training_arr_labels = np.load(\"training_arr_labels.npy\")\n",
    "print(training_arr_labels.shape)\n",
    "testing_arr = np.load(\"test_arr.npy\")\n",
    "print(testing_arr.shape)\n",
    "testing_arr_labels = np.load(\"test_arr_labels.npy\")\n",
    "print(testing_arr_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def convert_label_to_vector(label):\n",
    "    first_half, second_half = label.split(\" \")\n",
    "    return [ord(i) for i in first_half]\n",
    "def data_generator():\n",
    "    for label, vector in zip(training_arr_labels, training_arr):\n",
    "        label_vectors = [convert_label_to_vector(z.strip().strip('\\'\\\"')) for z in label[0].split(',')]\n",
    "        left = np.vstack(label_vectors)\n",
    "        right = np.vstack([vector]*len(label_vectors))\n",
    "        for l, r in zip(left, right):\n",
    "            ret = (np.hstack((r)).reshape((1, 1000)), np.hstack(l).reshape(1, 4))\n",
    "            yield ret\n",
    "\n",
    "def data_generator_test():\n",
    "    n = 0\n",
    "    for label, vector in zip(testing_arr_labels, testing_arr):\n",
    "        label_vectors = [convert_label_to_vector(z.strip().strip('\\'\\\"')) for z in label[0].split(',')]\n",
    "        left = np.vstack(label_vectors)\n",
    "        right = np.vstack([vector]*len(label_vectors))\n",
    "        for l, r in zip(left, right):\n",
    "            ret = (np.hstack(r).reshape((1, 1000)), np.hstack(l).reshape(1,4))\n",
    "            yield ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.0645229 ,  0.17206578,  0.27927458, -0.30743885,  0.13213426,\n",
       "          0.17168853, -0.04445799,  0.10521594, -0.19461322, -0.07855076,\n",
       "         -0.41951725, -0.09668623, -0.35180104,  0.01814128, -0.0385349 ,\n",
       "         -0.08269156, -0.21654539,  0.26963288,  0.26394212, -0.0769471 ,\n",
       "          0.08159757,  0.1462388 , -0.03166891,  0.02227308,  0.23033331,\n",
       "          0.17491078, -0.15494405,  0.13411523, -0.37758556, -0.01522811,\n",
       "         -0.06026023, -0.11446414, -0.1623046 ,  0.03186761,  0.21371846,\n",
       "         -0.02242558,  0.16906044, -0.02776215,  0.00679719,  0.06852875,\n",
       "          0.00765829,  0.02052856,  0.16629462,  0.02336159, -0.1593455 ,\n",
       "          0.01478121,  0.07531595,  0.01106454,  0.08919558,  0.09136292,\n",
       "         -0.08452553, -0.07023416,  0.13372375, -0.06224204,  0.19001652,\n",
       "         -0.05064945, -0.20634146, -0.3096862 , -0.04973361, -0.01662633,\n",
       "         -0.06698404,  0.03559001,  0.19376872,  0.00359708,  0.18056893,\n",
       "          0.09578311,  0.06466607,  0.35416147, -0.08304131,  0.05617613,\n",
       "         -0.0776866 , -0.03632496, -0.14589858, -0.0980787 , -0.04229461,\n",
       "          0.07439113,  0.18665218,  0.1849557 ,  0.0562208 , -0.19372487,\n",
       "         -0.04156989,  0.1001709 , -0.05243549,  0.1457601 , -0.0670488 ,\n",
       "          0.14433269, -0.04335813, -0.20650114, -0.19626045,  0.01099012,\n",
       "         -0.19049092, -0.19939014,  0.03532109, -0.17558794,  0.0579148 ,\n",
       "         -0.19178173, -0.13707128,  0.14264974, -0.1328977 ,  0.00447591,\n",
       "         -0.34543192,  0.04102907, -0.248671  , -0.13262582, -0.18089683,\n",
       "         -0.08615367, -0.00860593,  0.28305924, -0.02289435,  0.1024184 ,\n",
       "         -0.04493339, -0.00449479, -0.29109952, -0.37665388,  0.06102712,\n",
       "          0.0407731 , -0.14411916,  0.22946043, -0.14490585, -0.06623371,\n",
       "         -0.14636196,  0.03181517,  0.16016215, -0.16461012,  0.15794063,\n",
       "          0.13073352, -0.00351297,  0.00663088, -0.1299548 ,  0.07125796,\n",
       "         -0.24888968,  0.05542968, -0.042564  , -0.23876132, -0.12924813,\n",
       "          0.04285325, -0.11338359,  0.14381056, -0.04297849,  0.04826898,\n",
       "         -0.06443051,  0.09205509,  0.01300324, -0.17423874, -0.04451376,\n",
       "         -0.09337716, -0.15719424, -0.15450233,  0.15668942, -0.07168122,\n",
       "         -0.02175293, -0.12225726,  0.17096171,  0.2973196 ,  0.19104335,\n",
       "         -0.00378849, -0.3654229 ,  0.0162486 ,  0.34976017, -0.20584464,\n",
       "         -0.05368307,  0.04966899,  0.1349347 ,  0.03663543,  0.31591612,\n",
       "          0.03997342, -0.35050556,  0.00867961,  0.28322604,  0.02069269,\n",
       "          0.22504926,  0.02081792, -0.02414843,  0.2845899 ,  0.2344354 ,\n",
       "          0.02337351,  0.0490736 ,  0.11444117,  0.09901188,  0.16238657,\n",
       "          0.0037255 , -0.2064488 ,  0.11421786, -0.05495441, -0.24390484,\n",
       "         -0.18564944,  0.00727178, -0.17619765, -0.00067667,  0.25306657,\n",
       "          0.2071741 ,  0.1244211 , -0.05903974, -0.13991152, -0.03163762,\n",
       "          0.27814725, -0.02947781,  0.186744  ,  0.0512155 ,  0.08317693,\n",
       "          0.06178985, -0.1318236 ,  0.08875995, -0.29942825,  0.1191084 ,\n",
       "         -0.10610149,  0.08813018,  0.3791845 ,  0.24929704, -0.17880706,\n",
       "          0.13556603, -0.01151364, -0.03370264, -0.03057867,  0.17244901,\n",
       "         -0.0473397 , -0.10417782, -0.01832008,  0.33274052, -0.08113032,\n",
       "          0.03130675, -0.09974125,  0.08671948, -0.16131243, -0.10144433,\n",
       "          0.03609746,  0.19449203,  0.22629328, -0.3157238 ,  0.05481041,\n",
       "          0.04153366, -0.22913697, -0.49942634,  0.11216659,  0.00302858,\n",
       "          0.18154836,  0.14403564,  0.23042655, -0.32560495, -0.02126629,\n",
       "          0.00159505, -0.16161045,  0.08101083, -0.14079235,  0.1859223 ,\n",
       "          0.04412182,  0.05346243,  0.17788395, -0.18190494,  0.20608294,\n",
       "          0.01519912, -0.11081033,  0.29384956,  0.05634734, -0.05903041,\n",
       "         -0.16117269,  0.14181583, -0.24065149, -0.19086842,  0.04972392,\n",
       "         -0.35923702,  0.00671366,  0.16625147, -0.01504489,  0.15311867,\n",
       "          0.10061789, -0.1986644 , -0.23331569,  0.00314049,  0.10423901,\n",
       "         -0.03148615, -0.08717215, -0.103427  ,  0.15787691,  0.19111294,\n",
       "          0.24229877,  0.21014462,  0.18534735, -0.02879828, -0.14941026,\n",
       "         -0.48350316, -0.1550051 , -0.09725999,  0.17394985, -0.02862506,\n",
       "         -0.08251093, -0.14083052, -0.08829436,  0.03981893, -0.04420476,\n",
       "         -0.47742325, -0.10089617, -0.1678274 ,  0.13838163,  0.08499228,\n",
       "          0.01154703, -0.02717032,  0.06692367, -0.02746436, -0.01452473,\n",
       "         -0.0947611 , -0.09819219, -0.24766722, -0.01958951,  0.22066407,\n",
       "         -0.05539191, -0.08422495, -0.14325513,  0.01659541, -0.13796808,\n",
       "          0.05885712,  0.1243356 , -0.17819798,  0.24672185,  0.1715928 ,\n",
       "          0.14331505, -0.2531504 ,  0.07284447, -0.11003628,  0.06841117,\n",
       "          0.05024005, -0.0636792 , -0.1220948 ,  0.18894908, -0.11156482,\n",
       "          0.04861435,  0.12212975, -0.1900484 , -0.02244771,  0.02420302,\n",
       "          0.24820878, -0.07062759,  0.01091093, -0.12469929, -0.14792782,\n",
       "          0.2078772 , -0.12925796,  0.02407638, -0.09564152,  0.14548087,\n",
       "          0.09701248, -0.13485174,  0.07736851, -0.03136897,  0.14632206,\n",
       "          0.12486129, -0.10376154,  0.18954723, -0.20528887, -0.24808842,\n",
       "         -0.20515388, -0.15562247,  0.21884947, -0.12887722, -0.04357651,\n",
       "         -0.29750493, -0.2084605 ,  0.06388008, -0.19909628,  0.19116366,\n",
       "         -0.05198651,  0.21851744, -0.06041871,  0.08194118,  0.01871582,\n",
       "         -0.0976413 ,  0.13870165,  0.28159416, -0.01361517,  0.04080915,\n",
       "          0.08626985,  0.20536946,  0.06905577,  0.16499166,  0.145978  ,\n",
       "          0.00287552,  0.02713746, -0.08716147, -0.20554315,  0.0044835 ,\n",
       "          0.12731896,  0.16031425,  0.22646813, -0.04592736, -0.03005522,\n",
       "          0.0996539 , -0.07074561,  0.01466656, -0.0355995 ,  0.06910472,\n",
       "          0.20007688, -0.01130809,  0.18915759,  0.06504706, -0.13177429,\n",
       "         -0.01918073, -0.2521479 , -0.2249378 , -0.13102785, -0.01115469,\n",
       "         -0.08332017,  0.06790925, -0.05912757,  0.06970486, -0.15264143,\n",
       "         -0.04983708, -0.04192493, -0.09630363,  0.04428967,  0.19396037,\n",
       "          0.19373593, -0.0822238 , -0.04398883,  0.28404433, -0.17646267,\n",
       "         -0.12194431,  0.05920249,  0.18348934, -0.26867723,  0.11338343,\n",
       "         -0.01007069,  0.26281565,  0.03411639, -0.06931099,  0.17997421,\n",
       "         -0.04213481, -0.14323501, -0.00356998, -0.30444646, -0.03517051,\n",
       "          0.11660051, -0.25335458, -0.05345659, -0.14767446, -0.27483767,\n",
       "         -0.14335549, -0.01824896, -0.06170439, -0.03801385, -0.15242565,\n",
       "          0.2536787 , -0.02706456, -0.04787224, -0.36538517, -0.02962669,\n",
       "          0.2120336 , -0.14451241,  0.02661673, -0.06571019, -0.03066283,\n",
       "          0.2658806 ,  0.42964283, -0.16457668,  0.04157557, -0.06599656,\n",
       "         -0.03321166,  0.01834904, -0.07757426, -0.18303315,  0.11863913,\n",
       "         -0.01737653,  0.0548229 , -0.24683698, -0.06841089,  0.1039587 ,\n",
       "          0.0835639 ,  0.115178  ,  0.11935861,  0.130595  ,  0.00758054,\n",
       "         -0.20968604,  0.01432628,  0.18580295, -0.0299396 , -0.18423875,\n",
       "         -0.16515231,  0.05069305, -0.16967502,  0.33794013, -0.09854534,\n",
       "         -0.15556549, -0.08523528,  0.09029461, -0.01436592, -0.00884499,\n",
       "          0.17518239,  0.00255852,  0.12668079, -0.04995218, -0.0221044 ,\n",
       "          0.03866003, -0.05440696, -0.18321972,  0.06373133,  0.21985827,\n",
       "          0.17594716,  0.20922752,  0.20844664,  0.03623621, -0.16088751,\n",
       "          0.11652481,  0.02067543,  0.11734302, -0.16184306, -0.11640799,\n",
       "         -0.13217217,  0.07174283,  0.19771703,  0.00413675,  0.27765545,\n",
       "         -0.03423395,  0.15676475,  0.131734  ,  0.02960956, -0.0264005 ,\n",
       "         -0.18460958, -0.25737283, -0.17015818, -0.00356536, -0.19828416,\n",
       "          0.02823276, -0.01964238, -0.13570653, -0.10506875,  0.09742701,\n",
       "         -0.06893235,  0.02280494,  0.4253895 ,  0.14343598, -0.10910276,\n",
       "          0.03427663, -0.167999  , -0.2968947 ,  0.01445137, -0.24889307,\n",
       "          0.02585191,  0.03910444,  0.36999917, -0.15079966,  0.10390688,\n",
       "         -0.03872976, -0.32933787,  0.15373749, -0.06500401, -0.00177555,\n",
       "          0.01531651, -0.12535669,  0.14964193, -0.04434063,  0.07524357,\n",
       "          0.02847544, -0.0223431 ,  0.08439364, -0.10816106,  0.1864724 ,\n",
       "         -0.06040814,  0.08805452, -0.01703781,  0.13233043,  0.0823572 ,\n",
       "          0.09026796, -0.1471717 ,  0.06552439,  0.03223406, -0.12469596,\n",
       "          0.07677896, -0.17793736, -0.1139652 , -0.4724438 , -0.09259342,\n",
       "          0.20922324,  0.06834   , -0.07619902, -0.19884941,  0.09269996,\n",
       "         -0.15688342,  0.11889548, -0.1888257 ,  0.0637887 ,  0.0262712 ,\n",
       "          0.11383104, -0.10334008, -0.14629127,  0.13165273,  0.09978964,\n",
       "         -0.0571181 ,  0.06851841, -0.09431346, -0.0187252 ,  0.13077   ,\n",
       "          0.21074645, -0.15016252,  0.21476474,  0.3137067 ,  0.17718343,\n",
       "          0.10865332, -0.09877186,  0.23523776,  0.00584571, -0.22361888,\n",
       "          0.3486182 , -0.12776166,  0.1619636 ,  0.09864324, -0.05768027,\n",
       "         -0.16128916,  0.04987246, -0.19628592,  0.05154379,  0.06582421,\n",
       "          0.04460154,  0.05762483,  0.17146179, -0.02873369,  0.19217932,\n",
       "          0.04242558, -0.02163828,  0.08201383,  0.09325507,  0.12839036,\n",
       "          0.11327016,  0.15964268,  0.09271717,  0.11866705,  0.04046113,\n",
       "         -0.0630791 , -0.35652053, -0.19720565,  0.11443728,  0.08447518,\n",
       "         -0.07769702, -0.01072714, -0.27710488, -0.20847924, -0.06143758,\n",
       "          0.11503436,  0.24392378, -0.1298911 ,  0.08753411,  0.27555218,\n",
       "          0.15491723,  0.02032464, -0.00686202, -0.13947019, -0.00985862,\n",
       "          0.1350876 ,  0.3528135 ,  0.1986797 ,  0.07493496, -0.25602907,\n",
       "          0.05322074, -0.11135454,  0.00452376, -0.05449786, -0.08510722,\n",
       "          0.01899878,  0.19615938,  0.01778016,  0.03561616,  0.25011382,\n",
       "          0.00687486, -0.15041886, -0.03537271,  0.23362474,  0.20771684,\n",
       "         -0.23768583, -0.35526076,  0.12709546, -0.0311684 , -0.00563182,\n",
       "          0.04079852,  0.0377811 ,  0.25914726, -0.24959491,  0.27447218,\n",
       "          0.0305668 ,  0.20015173,  0.00412897, -0.17551011,  0.06050907,\n",
       "          0.10259492,  0.11120494,  0.45737275, -0.10094961, -0.21254009,\n",
       "         -0.08636504, -0.21201366,  0.00061916,  0.18939726, -0.09879111,\n",
       "          0.12645945,  0.00168827, -0.26991543,  0.12548903, -0.14848274,\n",
       "         -0.07050957,  0.00523936, -0.09230149, -0.34207413, -0.05928858,\n",
       "         -0.25771123,  0.06124369, -0.09884408, -0.09355614,  0.25088206,\n",
       "          0.14576529,  0.0860383 ,  0.13088758,  0.11454677,  0.07870667,\n",
       "         -0.15646829,  0.06396485, -0.1152275 , -0.02612964,  0.03317104,\n",
       "         -0.14949797,  0.04284417, -0.3333378 ,  0.08423755, -0.25432062,\n",
       "         -0.25617662, -0.00922912, -0.05953298, -0.36408633, -0.02139671,\n",
       "         -0.12481137, -0.10746057, -0.25195983,  0.16171584,  0.04456007,\n",
       "          0.14316949,  0.12845033,  0.02845929,  0.34244162, -0.08299213,\n",
       "          0.112466  , -0.01512923,  0.14950764,  0.03234437, -0.16725229,\n",
       "          0.0807811 ,  0.32914883, -0.07273998,  0.05857748, -0.17709161,\n",
       "          0.03872654,  0.04182598, -0.18259908,  0.08369403,  0.00830401,\n",
       "         -0.141529  , -0.02788421,  0.03379385, -0.18367231, -0.28968066,\n",
       "         -0.09868837,  0.01317624,  0.07446341,  0.03160488, -0.0264175 ,\n",
       "         -0.0829901 ,  0.10316995,  0.24010183, -0.24151853,  0.04552235,\n",
       "         -0.2112929 , -0.06216704,  0.05608466,  0.01575911,  0.10811224,\n",
       "          0.22066824,  0.01743211,  0.14443599,  0.1473248 ,  0.11038044,\n",
       "          0.11387893,  0.24033228,  0.12111147,  0.10757737,  0.09413528,\n",
       "         -0.10293186, -0.0401171 , -0.36588293, -0.12882376,  0.28882307,\n",
       "         -0.09958149,  0.0770793 ,  0.07953858,  0.33715877,  0.05559498,\n",
       "          0.0879916 , -0.05482965,  0.11792733, -0.01908221,  0.033142  ,\n",
       "         -0.04011862, -0.07781602, -0.13268687,  0.00867631,  0.09594036,\n",
       "         -0.1038119 , -0.06821138,  0.36429685, -0.02556488,  0.16358551,\n",
       "         -0.01442171, -0.12448715, -0.19018331, -0.09096112,  0.08139295,\n",
       "         -0.11413623,  0.00550558, -0.02025576,  0.1739195 ,  0.11441833,\n",
       "          0.04711745,  0.10308066,  0.20573154, -0.02386375, -0.21817815,\n",
       "         -0.18455677,  0.37083742,  0.03102865, -0.20169622,  0.19815376,\n",
       "          0.08430286,  0.22994459,  0.04071189, -0.0601789 , -0.10813928,\n",
       "         -0.07442543, -0.0486813 ,  0.00549895,  0.01786497,  0.18364869,\n",
       "         -0.22217914, -0.17823242,  0.25183252,  0.05377823, -0.12137841,\n",
       "         -0.14060338,  0.16567107, -0.01808627, -0.04995928, -0.01950325,\n",
       "         -0.12115163,  0.10043342,  0.31057727,  0.06513241,  0.10164272,\n",
       "          0.28501046,  0.1653823 , -0.06440631, -0.11976562, -0.04486097,\n",
       "         -0.15478599,  0.01316017,  0.39988282, -0.1892924 ,  0.06769365,\n",
       "         -0.08954134,  0.0590978 , -0.05048181, -0.14585155,  0.11132345,\n",
       "          0.1339564 , -0.05980626,  0.23630488,  0.01042783, -0.33205643,\n",
       "         -0.01433847,  0.18561244, -0.025371  ,  0.3135695 , -0.04398337,\n",
       "         -0.04448355,  0.20883402, -0.18833457, -0.04783942, -0.19412972,\n",
       "         -0.18300685, -0.06165469, -0.05822054, -0.08968666,  0.15701725,\n",
       "          0.14405769, -0.30310106,  0.2242676 ,  0.15089415, -0.04001307,\n",
       "          0.08355989, -0.19214155,  0.16252498, -0.02357888, -0.04673448,\n",
       "          0.04976586,  0.01405972, -0.07606626,  0.18616964,  0.291423  ,\n",
       "          0.00827706,  0.03569923,  0.09675671,  0.02355449, -0.16367927,\n",
       "          0.02092027, -0.06541702, -0.05714583,  0.30300736,  0.06221151,\n",
       "         -0.22411881, -0.06736848,  0.12215941,  0.21956225, -0.10363705,\n",
       "         -0.03597516,  0.3027774 ,  0.02059855,  0.10619493, -0.35093033,\n",
       "         -0.08290924, -0.18215702,  0.04250633,  0.16834305, -0.00315696,\n",
       "          0.11320566,  0.21088392, -0.12870231, -0.23391356,  0.11258935,\n",
       "          0.05759581, -0.08964117, -0.2578764 ,  0.19491799,  0.16860233,\n",
       "         -0.16465977,  0.13516936, -0.29909518,  0.00951849, -0.05970711,\n",
       "         -0.1723779 , -0.2302352 ,  0.06804078,  0.04895461, -0.11730923,\n",
       "          0.05696895,  0.12390327,  0.12275566, -0.08127016, -0.01065471,\n",
       "         -0.12215457,  0.285338  , -0.15150905, -0.13157876, -0.12300062,\n",
       "          0.09601666, -0.13892418,  0.28141737,  0.1092901 ,  0.06760278,\n",
       "          0.26195362,  0.05220512, -0.12543812, -0.08094075, -0.0137961 ,\n",
       "          0.10313232,  0.00801143, -0.08038767,  0.30404675,  0.03702764,\n",
       "          0.06230066, -0.0920537 , -0.1005165 , -0.17600736, -0.09101004,\n",
       "         -0.02749307,  0.19806957,  0.01848318,  0.03809359,  0.3402631 ,\n",
       "         -0.03729901, -0.07526735, -0.10315157,  0.26337644,  0.0105015 ,\n",
       "          0.08491882,  0.14561015, -0.12835562, -0.45320982, -0.06293774,\n",
       "          0.015885  , -0.15026222,  0.00894416,  0.07148685,  0.0031513 ,\n",
       "         -0.04385832,  0.24598193,  0.12963693, -0.02076383, -0.09773993]],\n",
       "       dtype=float32), array([[65, 48, 49, 72]]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = data_generator().next()\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RepeatDataset shapes: ((32, 1, 1000), (32, 1, 4)), types: (tf.int64, tf.int64)>\n",
      "<RepeatDataset shapes: ((128, 1, 1000), (128, 1, 4)), types: (tf.int64, tf.int64)>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "dataset.__iter__() is only supported when eager execution is enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-1a6d09d8673c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/data/ops/dataset_ops.pyc\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m       raise RuntimeError(\"dataset.__iter__() is only supported when eager \"\n\u001b[0m\u001b[1;32m    142\u001b[0m                          \"execution is enabled.\")\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: dataset.__iter__() is only supported when eager execution is enabled."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "#tf.disable_eager_execution()\n",
    "dataset = tf.data.Dataset.from_generator(data_generator, (tf.int64, tf.int64), (tf.TensorShape([1, 1000]), tf.TensorShape([1, 4])))\n",
    "test_dataset = tf.data.Dataset.from_generator(data_generator_test, (tf.int64, tf.int64), (tf.TensorShape([1, 1000]), tf.TensorShape([1, 4])))\n",
    "test_dataset = test_dataset.batch(128, drop_remainder=True).repeat()\n",
    "train_dataset = dataset.batch(32, drop_remainder=True).repeat()\n",
    "print(train_dataset)\n",
    "print(test_dataset)\n",
    "for x, y in train_dataset:\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_38 (Dense)             (None, None, 1000)        1001000   \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, None, 100)         100100    \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, None, 4)           404       \n",
      "=================================================================\n",
      "Total params: 1,101,504\n",
      "Trainable params: 1,101,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#train_dataset = tf.data.Dataset.zip((tf.data.Dataset.from_tensors((training_vectors[:300000], training_labels[:300000])), tf.data.Dataset.from_tensors((training_vectors[300000:], training_labels[300000:]))))\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1000, input_shape=(None, 1000)),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='relu')\n",
    "])\n",
    "saver = tf.train.Saver(max_to_keep=4, keep_checkpoint_every_n_hours=2)\n",
    "model.summary()\n",
    "model.compile(loss='mse',\n",
    "              optimizer=tf.train.AdamOptimizer(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "4000/4000 [==============================] - 1356s 339ms/step - loss: 1560.5498 - acc: 0.5962 - val_loss: 1287.2079 - val_acc: 0.6595\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=False,\n",
    "                                                 verbose=1)\n",
    "history = model.fit(train_dataset, epochs=1,\n",
    "                    validation_data=test_dataset, \n",
    "                    validation_steps=600,\n",
    "                   steps_per_epoch=4000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 82s 818ms/step\n",
      "Test Loss: 1328.19716919\n",
      "Test Accuracy: 0.89375\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset, steps=100)\n",
    "\n",
    "print('Test Loss: {}'.format(test_loss))\n",
    "print('Test Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import newaxis\n",
    "p = model.predict(np.vstack(testing_arr).reshape(-1, 1, 1000))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[65, 48, 49, 72]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-14b3b20529e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_vectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "for label, vector in zip(testing_arr_labels, testing_arr):\n",
    "    label_vectors = [convert_label_to_vector(z.strip().strip('\\'\\\"')) for z in label[0].split(',')]\n",
    "    print(label_vectors[0])\n",
    "    p = model.predict(np.vstack(vector).reshape(1, -1, 1000))\n",
    "    print([chr(i) for i in p[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
